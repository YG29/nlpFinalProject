{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-03-25T14:14:21.578848Z",
     "start_time": "2024-03-25T14:14:19.249723Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax. Perhaps you forgot a comma? (encoder.py, line 13)",
     "output_type": "error",
     "traceback": [
      "Traceback \u001B[0;36m(most recent call last)\u001B[0m:\n",
      "\u001B[0m  File \u001B[1;32m~/Library/Caches/pypoetry/virtualenvs/nlpfinalproject-E4blksoP-py3.11/lib/python3.11/site-packages/IPython/core/interactiveshell.py:3577\u001B[0m in \u001B[1;35mrun_code\u001B[0m\n    exec(code_obj, self.user_global_ns, self.user_ns)\u001B[0m\n",
      "\u001B[0;36m  Cell \u001B[0;32mIn[6], line 5\u001B[0;36m\n\u001B[0;31m    from encoder import Encoder\u001B[0;36m\n",
      "\u001B[0;36m  File \u001B[0;32m~/Documents/alexandria/RUG/ml/nlpProject/notebooks/../src/encoder.py:13\u001B[0;36m\u001B[0m\n\u001B[0;31m    Dense(hidden_dimension, activation = 'relu')\u001B[0m\n\u001B[0m    ^\u001B[0m\n\u001B[0;31mSyntaxError\u001B[0m\u001B[0;31m:\u001B[0m invalid syntax. Perhaps you forgot a comma?\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('../src')\n",
    "\n",
    "from positionalencoding import PositionalEncoding\n",
    "from encoder import Encoder\n",
    "from transformer import Transformer"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-25T14:14:29.445243Z",
     "start_time": "2024-03-25T14:14:29.436315Z"
    }
   },
   "id": "88388155ae3bb66"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "TRAIN_PADDED = '../data/clean/train_padded.csv'\n",
    "VAL_PADDED = '../data/clean/val_padded.csv'\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "MAX_SENTENCE = 50"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-25T14:09:10.620328Z",
     "start_time": "2024-03-25T14:09:10.613922Z"
    }
   },
   "id": "cd92740effc6f71b"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "#load and preprocess\n",
    "def load_preprocess(df_file_path, batch_size=BATCH_SIZE):\n",
    "    \n",
    "    # load data from csv\n",
    "    input_data = pd.read_csv(df_file_path)['inputs'].tolist()\n",
    "    target_data = pd.read_csv(df_file_path)['targets'].tolist()\n",
    "    \n",
    "    # create tensorflow dataset\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((input_data, target_data))\n",
    "    \n",
    "    # processing function\n",
    "    def preprocess(dat_input, dat_target):\n",
    "        dat_input = tf.cast(dat_input, tf.int64)\n",
    "        dat_target = tf.cast(dat_target, tf.int64)\n",
    "        return dat_input, dat_target\n",
    "    # apply processing function\n",
    "    dataset = dataset.map(preprocess)\n",
    "    \n",
    "    # batch and prefetch\n",
    "    dataset = dataset.batch(batch_size)\n",
    "    dataset = dataset.prefetch(tf.data.AUTOTUNE)\n",
    "    \n",
    "    return dataset"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-25T14:14:35.669617Z",
     "start_time": "2024-03-25T14:14:35.663263Z"
    }
   },
   "id": "1b61c52f3b91fba1"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-25 15:14:52.472000: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M2 Pro\n",
      "2024-03-25 15:14:52.472034: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 32.00 GB\n",
      "2024-03-25 15:14:52.472042: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 10.67 GB\n",
      "2024-03-25 15:14:52.472064: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2024-03-25 15:14:52.472093: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    }
   ],
   "source": [
    "train_dataset = load_preprocess(TRAIN_PADDED)\n",
    "val_dataset = load_preprocess(VAL_PADDED)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-25T14:14:57.447488Z",
     "start_time": "2024-03-25T14:14:36.724272Z"
    }
   },
   "id": "7421067302ad9953"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "def create_mask(input, target):\n",
    "    # encoding mask\n",
    "    encoding_padding_mask = tf.cast(tf.math.equal(input, 0), tf.float32)\n",
    "    encoding_padding_mask = encoding_padding_mask[:, tf.newaxis, tf.newaxis, :]\n",
    "    \n",
    "    # decoding mask\n",
    "    decoding_padding_mask = tf.cast(tf.math.equal(target, 0), tf.float32)\n",
    "    decoding_padding_mask = decoding_padding_mask[:, tf.newaxis, tf.newaxis, :]\n",
    "    \n",
    "    # future mask\n",
    "    future_mask = tf.linalg.band_part(tf.ones((1, None, None, None)), -1, 0)\n",
    "    future_mask = tf.maximum(decoding_padding_mask, future_mask)\n",
    "    \n",
    "    return encoding_padding_mask, future_mask, decoding_padding_mask"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-25T14:15:02.529013Z",
     "start_time": "2024-03-25T14:15:02.525914Z"
    }
   },
   "id": "54f20802d8065a03"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "# parameters\n",
    "num_layers = 2\n",
    "embedding_dimension = 10\n",
    "num_heads = 4\n",
    "ff_dimension = 4\n",
    "input_vocab_size = 900\n",
    "target_vocab_size = 900\n",
    "learning_rate = 0.2\n",
    "num_epochs = 200"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-25T14:15:04.069989Z",
     "start_time": "2024-03-25T14:15:04.062578Z"
    }
   },
   "id": "37afd92a7963d9c8"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Transformer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[11], line 2\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# model set up\u001B[39;00m\n\u001B[0;32m----> 2\u001B[0m model \u001B[38;5;241m=\u001B[39m \u001B[43mTransformer\u001B[49m(num_layers, embedding_dimension, num_heads, ff_dimension, input_vocab_size, target_vocab_size, max_len_input\u001B[38;5;241m=\u001B[39mMAX_SENTENCE, max_len_output\u001B[38;5;241m=\u001B[39mMAX_SENTENCE)\n\u001B[1;32m      3\u001B[0m loss_object \u001B[38;5;241m=\u001B[39m tf\u001B[38;5;241m.\u001B[39mkeras\u001B[38;5;241m.\u001B[39mlosses\u001B[38;5;241m.\u001B[39mSparseCategoricalCrossentropy(from_logits\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m, reduction\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mnone\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m      4\u001B[0m optimizer \u001B[38;5;241m=\u001B[39m tf\u001B[38;5;241m.\u001B[39mkeras\u001B[38;5;241m.\u001B[39moptimizers\u001B[38;5;241m.\u001B[39mAdam(learning_rate)\n",
      "\u001B[0;31mNameError\u001B[0m: name 'Transformer' is not defined"
     ]
    }
   ],
   "source": [
    "# model set up\n",
    "model = Transformer(num_layers, embedding_dimension, num_heads, ff_dimension, input_vocab_size, target_vocab_size, max_len_input=MAX_SENTENCE, max_len_output=MAX_SENTENCE)\n",
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True, reduction='none')\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-25T14:15:05.459779Z",
     "start_time": "2024-03-25T14:15:05.289505Z"
    }
   },
   "id": "e0e73599ff7fb2f8"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# training loop\n",
    "for epoch in range(num_epochs):\n",
    "    for inputs, targets in train_dataset:\n",
    "        # create the masks\n",
    "        encoding_padding_mask, future_mask, decoding_padding_mask = create_mask(inputs,targets)\n",
    "        \n",
    "        with tf.GradientTape() as tape:\n",
    "            predictions, _, _ = model(inputs, targets, True, encoding_padding_mask, future_mask, decoding_padding_mask)\n",
    "            loss = loss_object(targets, predictions)\n",
    "            \n",
    "        gradients = tape.gradient(loss, model.trainable_variables)\n",
    "        optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "        \n",
    "    # validation loop\n",
    "    total_val_loss = 0.0\n",
    "    num_val_batches = 0\n",
    "    for inputs, targets in val_dataset:\n",
    "        encoding_padding_mask, future_mask, decoding_padding_mask = create_mask(inputs, targets)\n",
    "        predictions, _, _ = model(inputs, targets, False, encoding_padding_mask, future_mask, decoding_padding_mask)\n",
    "        val_loss = loss_object(targets, predictions)\n",
    "        total_val_loss += val_loss.np().sum()\n",
    "        num_val_batches += 1\n",
    "        \n",
    "    # print average validation loss\n",
    "    ave_val_loss = total_val_loss / num_val_batches\n",
    "    print(f\"Epoch {epoch+1}, Validation Loss: {ave_val_loss:.4f}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-23T11:43:45.485018Z",
     "start_time": "2024-03-23T11:43:45.484887Z"
    }
   },
   "id": "3743a2d3d9ed19d8"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "c4dffa03baa56d02"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
